
```{r}
library(tidyverse)
library(tidytext)
library(janeaustenr)
```

Look at sentiments
```{r}
get_sentiments("afinn") %>% 
  filter(value == 4)
# 5 = very positive, -5 = very negative
```

```{r}
get_sentiments("bing")
# binary value
```

```{r}
get_sentiments("loughran") %>% 
  distinct(sentiment)
# classify financial documents
```

```{r}
get_sentiments("nrc") %>% 
  head(100)
# multiple sentiments for words, 10 sentiments
```

Set up text without stop words, id'ed by sentence
```{r}
book_pride <- tibble(
  text = prideprejudice,
  sentence = 1:length(prideprejudice)
) %>% 
  unnest_tokens(word, text) %>% 
  anti_join(stop_words)


```

Add lexicon to a text - keep all words
```{r}
book_pride %>% 
  left_join(get_sentiments("bing"))
```

Add lexicon to text - retaining only words with a sentiment
```{r}
book_sentiment <- book_pride %>% 
  inner_join(get_sentiments("bing"))
```

Most common positive words
```{r}
book_sentiment %>% 
  filter(sentiment == "positive") %>% 
  count(word, sort = T)
```

# Task
Find the most common positive, negative and neutral words in the book “Emma”. Use the loughran sentiment lexicon.

```{r}
book_emma <- tibble(
  text = emma,
  sentence = 1:length(emma)
) %>% 
  unnest_tokens(output = word, input = text, token = "words")

emma_sentiment <- book_emma %>% 
  left_join(get_sentiments("loughran"))

emma_sentiment %>% 
  filter(sentiment == "positive")
```

# Average sentiment per sentence

Use affin for numeric scores
```{r}
book_sentiment <- book_pride %>% 
  inner_join(get_sentiments("afinn"))
```
Find average value
```{r}
sentence_sentiments <- book_sentiment %>% 
  group_by(sentence) %>% 
  summarise(mean_sentiment = mean(value))

sentence_sentiments
```

Visualise average sentiment
```{r}
ggplot(sentence_sentiments) +
  aes(x = sentence, y = mean_sentiment) +
  geom_point(alpha = 0.1) +
  geom_smooth()
```

